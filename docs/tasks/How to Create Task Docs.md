

# ğŸ“˜ How to Create Task Docs (`docs/tasks/*.md`)

## ğŸ¯ Objective

This document explains how to create and maintain structured task documentation using DigitalOcean Navigator GPT (DON). Each task should have its own `.md` file inside `docs/tasks/`, and DON will help generate it based on your PRD, code changes, and DigitalOcean official docs.

---

## ğŸ§© Folder Structure Example

```

docs/
â”œâ”€ tasks/
â”‚   â”œâ”€ task-13.1-chatbot-ui.md
â”‚   â”œâ”€ task-14.2-stt-integration.md
â”‚   â”œâ”€ task-14.4-tts-integration.md
â”‚   â”œâ”€ README.md â† You are here

````

---

## ğŸ§µ One GPT Thread Per Task

Each task (e.g., â€œTask 14.2 â€“ Implement STT Integrationâ€) should be handled in **its own GPT thread**. This helps DON focus and gives you a single source of truth per implementation step.

---

## ğŸ›  Step-by-Step Instructions

### âœ… Step 1: Create a New GPT Thread

Use the **DigitalOcean Navigator GPT**. Then paste the following prompt:

---

### ğŸ§  Template Prompt to Give DON:
```plaintext
Iâ€™m working on Task 14.2 â€“ Implement STT Integration using OpenAI Whisper.

ğŸ“„ PRD Summary:
â€œIntegrate frontend mic capture using MediaRecorder. Send audio to backend endpoint `/api/v1/stt`, which forwards it to OpenAI Whisper and returns transcribed text to the chatbot agent.â€

ğŸ”— Reference Doc:
https://www.digitalocean.com/community/tutorials/realtime-audio-translation-using-openai-api-on-open-webui

ğŸ§© Updated Files:
- `components/VoiceButton.jsx`
- `routes/api/stt.js`

ğŸ“¦ Roo Code has made these updates. Please create a `docs/tasks/task-14.2-stt-integration.md` file with:
- Task title and description
- Implementation summary
- DO documentation link(s)
- Subplan prompt
- Lesson plan prompt
- Acceptance criteria
- Open issues or follow-up
````

---

### âœ… Step 2: Review GPT Output

DON will return a full Markdown block. Copy that output into your project repo as:

```
docs/tasks/task-14.2-stt-integration.md
```

---

## ğŸ§ª Example Output File (Excerpt)

```markdown
# ğŸ§  Task 14.2 â€“ Implement STT Integration

## ğŸ¯ Objective
Implement frontend mic capture and backend routing to OpenAI Whisper API to convert speech to text.

## ğŸ”— References
- [DigitalOcean Whisper STT Guide](https://www.digitalocean.com/community/tutorials/realtime-audio-translation-using-openai-api-on-open-webui)

## ğŸ“ Files Involved
- `components/VoiceButton.jsx`
- `routes/api/stt.js`

## âœ… Acceptance Criteria
- Mic icon triggers recording
- Whisper API returns accurate transcription
- Latency under 3 seconds

## ğŸ“˜ Subplan Prompt
â€œCreate a step-by-step plan to integrate browser audio recording with MediaRecorder and call Whisper API using backend routing at `/api/v1/stt`.â€

## ğŸ“ Lesson Plan Prompt
â€œTeach how to build a full STT pipeline using OpenAI Whisper API and the DO Whisper guide. Include audio UX, backend routing, and fallback handling.â€
```

---

## ğŸ“Œ Tips

* Include GitHub commit hashes if possible
* Save the GPT thread link in a comments section of the file for traceability
* Keep task names aligned with PRD task numbers

---

## ğŸ§° Optional Tools

* [doctl CLI](https://docs.digitalocean.com/reference/doctl/)
* [GradientAI KB API Guide](https://docs.digitalocean.com/products/gradientai-platform/how-to/create-manage-agent-knowledge-bases/)

---

For any questions, paste this README into your GPT thread to remind DON what format to use.

```

---


